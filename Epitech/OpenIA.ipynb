{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c985b6b3-b9bb-43dc-8e61-b8f3917e034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ea9b816-d982-4e9d-9f41-988c1ce66db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d140563f-9e59-4c81-87a4-4cad052edf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\",\n",
    "  prompt=\"ecrit moi un poeme pour Tom\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  # top_p=1.0,\n",
    "  # frequency_penalty=0.0,\n",
    "  # presence_penalty=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fe5d4b1-404c-4104-816e-8d11e1cc27a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tom, tu es mon ami,\n",
      "Mon ami fidèle et sincère,\n",
      "Tu me fais rire et me fais sourire\n",
      "Et tu me donnes de l'espoir.\n",
      "\n",
      "Tu es toujours là pour m'écouter,\n",
      "Même quand je ne veux pas parler.\n",
      "Tu me donnes de la force et de la confiance\n",
      "Et tu me montres le chemin.\n",
      "\n",
      "Tu m'as aidé à traverser les tempêtes,\n",
      "Même quand le vent était fort.\n",
      "Tu m'as donné des conseils\n",
      "Et tu as toujours été là pour moi.\n",
      "\n",
      "Tu es mon ami, mon confident,\n",
      "Tu es toujours là pour me soutenir.\n",
      "Je serai toujours là pour toi,\n",
      "Pour te soutenir et te guider.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c79044f-77a4-4b08-82e0-24e409655b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8f37fa1-bc2f-49c4-8e4a-ec09836f81e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 10 chanson les plus écoutaient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. \"Shape of You\" - Ed Sheeran\n",
      "2. \"Despacito\" - Luis Fonsi ft. Daddy Yankee\n",
      "3. \"Havana\" - Camila Cabello ft. Young Thug\n",
      "4. \"Rockstar\" - Post Malone ft. 21 Savage\n",
      "5. \"Perfect\" - Ed Sheeran\n",
      "6. \"Closer\" - The Chainsmokers ft. Halsey\n",
      "7. \"Something Just Like This\" - The Chainsmokers & Coldplay\n",
      "8. \"Attention\" - Charlie Puth\n",
      "9. \"I'm the One\" - DJ Khaled ft. Justin Bieber, Quavo, Chance the Rapper, & Lil Wayne\n",
      "10. \"Thunder\" - Imagine Dragons\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " javascript interroger api coingecko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "// Exemple avec jQuery\n",
      "$.ajax({\n",
      "  url: 'https://api.coingecko.com/api/v3/coins/list',\n",
      "  type: 'GET',\n",
      "  success: function(data) {\n",
      "    console.log(data);\n",
      "  }\n",
      "});\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " avec axios\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Axios est un client HTTP basé sur le promesse qui permet aux développeurs de faire des requêtes HTTP depuis leur application. Il est très facile à utiliser et supporte les méthodes HTTP courantes telles que GET, POST, PUT, DELETE et PATCH. Il peut également être utilisé pour envoyer des données JSON et des fichiers binaires. Axios peut être utilisé pour effectuer des requêtes asynchrones et offre une gestion des erreurs intégrée. Il peut également être utilisé pour créer des intercepteurs qui peuvent être utilisés pour modifier ou annuler des requêtes avant qu'elles ne soient envoyées.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " javascript axios call instagram api\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "axios.get('https://api.instagram.com/v1/users/self/media/recent', {\n",
      "  params: {\n",
      "    access_token: 'ACCESS-TOKEN'\n",
      "  }\n",
      "})\n",
      ".then(function (response) {\n",
      "  console.log(response.data);\n",
      "})\n",
      ".catch(function (error) {\n",
      "  console.log(error);\n",
      "});\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " javascript axios call instagram api and get most liked posts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "const axios = require('axios');\n",
      "\n",
      "const getMostLikedPosts = async (username) => {\n",
      "  try {\n",
      "    const res = await axios.get(\n",
      "      `https://www.instagram.com/${username}/?__a=1`\n",
      "    );\n",
      "    const edges = res.data.graphql.user.edge_owner_to_timeline_media.edges;\n",
      "    const mostLikedPosts = edges\n",
      "      .sort((a, b) => b.node.edge_liked_by.count - a.node.edge_liked_by.count)\n",
      "      .slice(0, 10);\n",
      "    return mostLikedPosts;\n",
      "  } catch (err) {\n",
      "    console.log(err);\n",
      "  }\n",
      "};\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " exit\n"
     ]
    }
   ],
   "source": [
    "run = True\n",
    "while run:\n",
    "    text = input()\n",
    "    if text == \"exit\":\n",
    "        run = False\n",
    "    else:\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt=text,\n",
    "            temperature=0.5,\n",
    "            max_tokens=256,\n",
    "            # top_p=1.0,\n",
    "            # frequency_penalty=0.0,\n",
    "            # presence_penalty=0.0\n",
    "        )\n",
    "        print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d0da6-a216-49bd-9ba6-6a5bd6f915ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
